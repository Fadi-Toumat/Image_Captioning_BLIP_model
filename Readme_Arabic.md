# تطبيق تسمية الصور باستخدام نموذج BLIP

## نظرة عامة

هذا المشروع يقدم تطبيق ويب بسيطًا لتسمية الصور (Image Captioning) باستخدام نموذج BLIP (Bootstrapping Language-Image Pre-training) من مكتبة Hugging Face Transformers. يتيح لك التطبيق تحميل صورة، ثم يقوم النموذج بتوليد وصف نصي تلقائي لهذه الصورة.

**تم تصميم هذا التطبيق واختباره بشكل أساسي على [Google Colab](https://colab.research.google.com/)، ويوصى بشدة بتشغيله هناك للاستفادة من موارده المجانية (خاصة وحدات معالجة الرسوميات GPU) وسهولة الإعداد.**

## الميزات

* توليد تعليقات وصفية للصور.
* واجهة مستخدم بديهية مبنية باستخدام Gradio.
* يدعم تشغيل النموذج على وحدات معالجة الرسوميات (GPU) لتحسين الأداء.

## كيفية التشغيل (في Google Colab)

**لتحقيق أفضل أداء، يوصى بتمكين T4 GPU في Google Colab:**
* في شريط القوائم العلوي، انقر على `وقت التشغيل (Runtime)` -> `تغيير نوع وقت التشغيل (Change runtime type)`.
* اختر `T4 GPU` كـ `المسرّع (Hardware accelerator)`.

**خطوات تشغيل التطبيق:**

1.  **افتح دفتر ملاحظات Google Colab جديدًا.**
2.  **في الخلية الأولى، قم بتثبيت المكتبات المطلوبة:**
    ```bash
    !pip install gradio transformers torch numpy Pillow
    ```
3.  **في خلية منفصلة، قم بلصق الكود البرمجي لتطبيق `app.py`** (الموجود في هذا المستودع).
4.  **قم بتشغيل هذه الخلية.** سيقوم Gradio بإنشاء رابط عام (Public URL) في مخرج الخلية (مثلاً `https://xxxxxxxx.gradio.live`).
5.  **انقر على الرابط** لفتح التطبيق في متصفحك.

## المكونات الرئيسية

* **`app.py`**: ملف Python الرئيسي الذي يحتوي على كود تطبيق Gradio.
* **`requirements.txt`**: قائمة بالمكتبات والتبعيات المطلوبة.
* **نموذج BLIP**: `Salesforce/blip-image-captioning-base` المستخدم لتوليد التسميات.

## الترخيص

هذا المشروع مرخص بموجب ترخيص MIT. انظر ملف [LICENSE](LICENSE) لمزيد من التفاصيل.
